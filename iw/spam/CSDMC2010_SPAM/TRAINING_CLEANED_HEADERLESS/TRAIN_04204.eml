>>>>> "tp" == tim peters  writes:

  >> the false positive rate is 0-3%.  (finally!  i had to scrub a
  >> bunch of previously unnoticed spam from my inbox.)  both
  >> collections have about 1100 messages.

  tp> does this mean you trained on about 1100 of each?

the total collections are 1100 messages.  i trained with 1100/5
messages. 

  tp> can't guess.  you're in a good position to start adding more
  tp> headers into the analysis, though.  for example, an easy start
  tp> would be to uncomment the header-counting lines in tokenize()
  tp> (look for "anthony").  likely the most valuable thing it's
  tp> missing then is some special parsing and tagging of received
  tp> headers.

i tried the "anthony" stuff, but it didn't make any appreciable
difference that i could see from staring at the false negative rate.
the numbers are big enough that a quick eyeball suffices.

then i tried a dirt simple tokenizer for the headers that tokenize the
words in the header and emitted like this "%s: %s" % (hdr, word).
that worked too well :-).  the received and date headers helped the
classifier discover that most of my spam is old and most of my ham is
new.

so i tried a slightly more complex one that skipped received, data,
and x-from_, which all contained timestamps.  i also skipped the x-vm-
headers that my mail reader added:

class mytokenizer(tokenizer):

    skip = {'received': 1,
            'date': 1,
            'x-from_': 1,
            }

    def tokenize_headers(self, msg):
        for k, v in msg.items():
            k = k.lower()
            if k in self.skip or k.startswith('x-vm'):
                continue
            for w in subject_word_re.findall(v):
                for t in tokenize_word(w):
                    yield "%s:%s" % (k, t)

this did moderately better.  the false negative rate is 7-21% over the
tests performed so far.  this is versus 11-28% for the previous test
run that used the timtest header tokenizer.

it's interesting to see that the best descriminators are all ham
discriminators.  there's not a single spam-indicator in the list.
most of the discriminators are header fields.  one thing to note is
that the presence of mailman-generated headers is a strong non-spam
indicator.  that matches my intuition: i got an awful lot of
mailman-generated mail, and those lists are pretty good at surpressing
spam.  the other thing is that i get a lot of ham from people who use
xemacs.  that's probably barry, guido, fred, and me :-).

one final note.  it looks like many of the false positives are from
people i've never met with questions about shakespeare.  they often
start with stuff like:

> dear sir/madam,
> 
> may i please take some of your precious time to ask you to help me to find a
> solution to a problem that is worrying me greatly. i am old science student

i guess that reads a lot like spam :-(.

jeremy


238 hams & 221 spams
    false positive: 2.10084033613
    false negative: 9.50226244344
    new false positives: []
    new false negatives: []

    best discriminators:
        'x-mailscanner:clean' 671 0.0483425
        'x-spam-status:in_rep_to' 679 0.01
        'delivered-to:skip:s 10' 691 0.0829876
        'x-mailer:lucid' 699 0.01
        'x-mailer:xemacs' 699 0.01
        'x-mailer:patch' 699 0.01
        'x-mailer:under' 709 0.01
        'x-mailscanner:found' 716 0.0479124
        'cc:zope.com' 718 0.01
        "i'll" 750 0.01
        'references:skip:1 20' 767 0.01
        'rossum' 795 0.01
        'x-spam-status:skip:s 10' 825 0.01
        'van' 850 0.01
        'http0:zope' 869 0.01
        'email addr:zope' 883 0.01
        'from:python.org' 895 0.01
        'to:jeremy' 902 0.185401
        'zope' 984 0.01
        'list-archive:skip:m 10' 1058 0.01
        'list-subscribe:skip:m 10' 1058 0.01
        'list-unsubscribe:skip:m 10' 1058 0.01
        'from:zope.com' 1098 0.01
        'return-path:zope.com' 1115 0.01
        'wrote:' 1129 0.01
        'jeremy' 1150 0.01
        'email addr:python' 1257 0.01
        'x-mailman-version:2.0.13' 1311 0.01
        'x-mailman-version:101270' 1395 0.01
        'python' 1401 0.01

